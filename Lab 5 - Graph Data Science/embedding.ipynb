{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "<p>\n",
        "  <a href=\"https://colab.research.google.com/github/neo4j-partners/hands-on-lab-neo4j-and-vertex-ai/blob/main/Lab%205%20-%20Graph%20Data%20Science/embedding.ipynb\" target=\"_blank\">\n",
        "    <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "  </a>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtcD7PrPzSqE"
      },
      "source": [
        "# Install Prerequisites\n",
        "First off, you'll also need to install a few packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwKogqD_He_e"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade neo4j\n",
        "!pip install --quiet google-cloud-storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdMFRbqGzSqF"
      },
      "source": [
        "# Working with Neo4j\n",
        "You'll need to enter the credentials from your Neo4j instance below.\n",
        "\n",
        "The default DB_NAME is always neo4j."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P41l_P4zzSqF"
      },
      "outputs": [],
      "source": [
        "DB_URL = 'neo4j://35.237.130.165:7687'\n",
        "DB_USER = 'neo4j'\n",
        "DB_PASS = 'foo123'\n",
        "DB_NAME = 'neo4j'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lUkSvmozSqF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "driver = GraphDatabase.driver(DB_URL, auth=(DB_USER, DB_PASS))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtJy4eO_zSqF"
      },
      "source": [
        "First we're going to create an in memory graph represtation of the data in Neo4j Graph Data Science (GDS)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URRShWv0zSqG"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.read_transaction(\n",
        "    lambda tx: tx.run(\n",
        "      \"\"\"\n",
        "CALL gds.graph.project(\n",
        "    'mygraph',\n",
        "    ['Company', 'Manager', 'Holding'],\n",
        "    {\n",
        "        OWNS: {orientation: 'UNDIRECTED'},\n",
        "        PARTOF: {orientation: 'UNDIRECTED'}\n",
        "    }\n",
        ")\n",
        "YIELD\n",
        "    graphName AS graph,\n",
        "    relationshipProjection AS readProjection,\n",
        "    nodeCount AS nodes,\n",
        "    relationshipCount AS rels\n",
        "      \"\"\"\n",
        "    ).data()\n",
        "  )\n",
        "df = pd.DataFrame(result)\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFwZUeZY0jd7"
      },
      "source": [
        "Note, if you get an error saying the graph already exists, that's probably because you ran this code before. You can destroy it using this command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bxCuwC_0gWZ"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.read_transaction(\n",
        "    lambda tx: tx.run(\n",
        "      \"\"\"\n",
        "      CALL gds.graph.drop('mygraph')\n",
        "      \"\"\"\n",
        "    ).data()\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnnO932bBexn"
      },
      "source": [
        "Now, let's list the details of the graph to make sure the projection was created as we want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZBPLijbrSCt"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.read_transaction(\n",
        "    lambda tx: tx.run(\n",
        "      \"\"\"\n",
        "      CALL gds.graph.list()\n",
        "      \"\"\"\n",
        "    ).data()\n",
        "  )\n",
        "  print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pFaTeUSzSqG"
      },
      "source": [
        "Now we can generate an embedding from that graph. This is a new feature we can use in our predictions. We're using FastRP, which is a more full featured and higher performance of Node2Vec. You can learn more about that [here](https://neo4j.com/docs/graph-data-science/current/algorithms/fastrp/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVxhVtTq4Kfc"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.read_transaction(\n",
        "    lambda tx: tx.run(\n",
        "      \"\"\"\n",
        "        CALL gds.fastRP.mutate('mygraph',{\n",
        "        embeddingDimension: 16,\n",
        "        randomSeed: 1,\n",
        "        mutateProperty:'embedding'\n",
        "        })\n",
        "      \"\"\"\n",
        "    ).data()\n",
        "  )\n",
        "df = pd.DataFrame(result)\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GR9GCbFitFy"
      },
      "source": [
        "That creates an embedding for each node type.  However, we only want the embedding on the nodes of type holding.\n",
        "\n",
        "We're going to take the embedding from our projection and write it to the holding nodes in the underlying database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-EKqaR-inUe"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.run(\n",
        "    \"\"\"\n",
        "      CALL gds.graph.writeNodeProperties('mygraph', ['embedding'], ['Holding'])\n",
        "      YIELD writeMillis\n",
        "    \"\"\"\n",
        "  )\n",
        "  print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLTjaLlMzSqH"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.read_transaction(\n",
        "    lambda tx: tx.run(\n",
        "      \"\"\"\n",
        "        MATCH (n:Holding) RETURN n\n",
        "      \"\"\"\n",
        "    ).data()\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGeVDYfrCEZx"
      },
      "source": [
        "Note that this query will take 2-3 minutes to run as it's grabbing nearly half a million nodes along with all their properties and our new embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUpaQ69smfJ9"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame([dict(record.get('n')) for record in result])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND0BKcgNDPgH"
      },
      "source": [
        "Note that the embedding row is an array. To make this dataset more consumable, we should flatten that out into multiple individual features: embedding_0, embedding_1, ... embedding_n.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W11q18eTC6-N"
      },
      "outputs": [],
      "source": [
        "embeddings = pd.DataFrame(df['embedding'].values.tolist()).add_prefix(\"embedding_\")\n",
        "merged = df.drop(columns=['embedding']).merge(embeddings, left_index=True, right_index=True)\n",
        "merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ooXlcpRbFd0"
      },
      "source": [
        "Now that we have the data formatted properly, let's split it into a training and a testing set and write those to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdPgEiDdDu-B"
      },
      "outputs": [],
      "source": [
        "df = merged\n",
        "\n",
        "train = df.loc[df['reportCalendarOrQuarter'] == '03-31-2021']\n",
        "train = train.append(df.loc[df['reportCalendarOrQuarter'] == '06-30-2021'])\n",
        "train.to_csv('train.csv', index=False)\n",
        "\n",
        "test = df.loc[df['reportCalendarOrQuarter'] == '09-30-2021']\n",
        "test.to_csv('test.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeK8OgtiAC7f"
      },
      "source": [
        "# Authenticate your Google Cloud Account\n",
        "Now let's write the file to Google Cloud Storage so we can use it in our model.  To do so, we must first authenticate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jU-jhjRjAC7f"
      },
      "outputs": [],
      "source": [
        "# Edit these variables!\n",
        "PROJECT_ID = 'YOUR-PROJECT-ID'\n",
        "STORAGE_BUCKET = 'NAME-OF-BUCKET-TO-CREATE'\n",
        "\n",
        "# You can leave these defaults\n",
        "REGION = 'us-central1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIZFbwc0EygT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GCLOUD_PROJECT'] = PROJECT_ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Yd7Him2FA0-"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import auth as google_auth\n",
        "    google_auth.authenticate_user()\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azb1inEVAC7f"
      },
      "source": [
        "# Upload to Google Cloud Storage\n",
        "Now we can upload our data sets to our bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRKBGEi3AC7f"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "client = storage.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9Y4HhC3AC7f"
      },
      "outputs": [],
      "source": [
        "bucket = client.bucket(STORAGE_BUCKET)\n",
        "bucket.location=REGION\n",
        "client.create_bucket(bucket)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8_owAf-AC7g"
      },
      "outputs": [],
      "source": [
        "# Upload our files to that bucket\n",
        "for filename in ['train.csv', 'test.csv']:\n",
        "    upload_path = os.path.join('embedding', filename)\n",
        "    blob = bucket.blob(upload_path)\n",
        "    blob.upload_from_filename(filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "embedding.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
