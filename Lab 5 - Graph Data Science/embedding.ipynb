{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "<p>\n",
        "  <a href=\"https://colab.research.google.com/github/neo4j-partners/hands-on-lab-neo4j-and-vertex-ai/blob/main/Lab%205%20-%20Graph%20Data%20Science/embedding.ipynb\" target=\"_blank\">\n",
        "    <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "  </a>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtcD7PrPzSqE"
      },
      "source": [
        "First off, you'll also need to install a few packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwKogqD_He_e"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade neo4j\n",
        "!pip install --quiet google-cloud-storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdMFRbqGzSqF"
      },
      "source": [
        "You'll need to enter the credentials from your Neo4j instance below.\n",
        "\n",
        "The default DB_NAME is always neo4j."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P41l_P4zzSqF"
      },
      "outputs": [],
      "source": [
        "DB_URL = \"neo4j://35.237.130.165:7687\"\n",
        "DB_USER = \"neo4j\"\n",
        "DB_PASS = \"foo123\"\n",
        "DB_NAME = \"neo4j\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lUkSvmozSqF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "driver = GraphDatabase.driver(DB_URL, auth=(DB_USER, DB_PASS))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtJy4eO_zSqF"
      },
      "source": [
        "First we're going to create an in memory graph represtation of the data in Neo4j Graph Data Science (GDS)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "URRShWv0zSqG",
        "outputId": "d529db22-c718-4577-873d-2cc28cec9d40"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.read_transaction(\n",
        "    lambda tx: tx.run(\n",
        "      \"\"\"\n",
        "CALL gds.graph.project(\n",
        "    'mygraph',\n",
        "    ['Company', 'Manager', 'Holding'],\n",
        "    {\n",
        "        OWNS: {orientation: 'UNDIRECTED'},\n",
        "        PARTOF: {orientation: 'UNDIRECTED'}\n",
        "    }\n",
        ")\n",
        "YIELD\n",
        "    graphName AS graph,\n",
        "    relationshipProjection AS readProjection,\n",
        "    nodeCount AS nodes,\n",
        "    relationshipCount AS rels\n",
        "      \"\"\"\n",
        "    ).data()\n",
        "  )\n",
        "df = pd.DataFrame(result)\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFwZUeZY0jd7"
      },
      "source": [
        "Note, if you get an error saying the graph already exists, that's probably because you ran this code before. You can destroy it using this command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bxCuwC_0gWZ"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.read_transaction(\n",
        "    lambda tx: tx.run(\n",
        "      \"\"\"\n",
        "      CALL gds.graph.drop('mygraph')\n",
        "      \"\"\"\n",
        "    ).data()\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZBPLijbrSCt",
        "outputId": "41d6e926-d560-436b-c8b5-02ba483488ca"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.read_transaction(\n",
        "    lambda tx: tx.run(\n",
        "      \"\"\"\n",
        "      CALL gds.graph.list()\n",
        "      \"\"\"\n",
        "    ).data()\n",
        "  )\n",
        "  print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pFaTeUSzSqG"
      },
      "source": [
        "Now we can generate an embedding from that graph. This is a new feature we can use in our predictions. We're using FastRP, which is a more full featured and higher performance of Node2Vec. You can learn more about that [here](https://neo4j.com/docs/graph-data-science/current/algorithms/fastrp/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "VVxhVtTq4Kfc",
        "outputId": "f405f0d8-de48-450a-f2cd-d06bc3aefcb1"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.read_transaction(\n",
        "    lambda tx: tx.run(\n",
        "      \"\"\"\n",
        "        CALL gds.fastRP.mutate('mygraph',{\n",
        "        embeddingDimension: 16,\n",
        "        randomSeed: 1, \n",
        "        mutateProperty:'embedding'\n",
        "        })\n",
        "      \"\"\"\n",
        "    ).data()\n",
        "  )\n",
        "df = pd.DataFrame(result)\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GR9GCbFitFy"
      },
      "source": [
        "That creates an embedding for each node type.  However, we only want the embedding on the nodes of type holding.\n",
        "\n",
        "We're going to take the embedding from our projection and write it to the holding nodes in the underlying database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-EKqaR-inUe",
        "outputId": "20294ec1-62a8-4b8b-8b52-ff62600610da"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.run(\n",
        "    \"\"\"\n",
        "      CALL gds.graph.writeNodeProperties('mygraph', ['embedding'], ['Holding'])\n",
        "      YIELD writeMillis\n",
        "    \"\"\"\n",
        "  )\n",
        "  print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLTjaLlMzSqH"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.read_transaction(\n",
        "    lambda tx: tx.run(\n",
        "      \"\"\"\n",
        "        MATCH (n:Holding) RETURN n LIMIT 100\n",
        "      \"\"\"\n",
        "    ).data()\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "WUpaQ69smfJ9",
        "outputId": "9beefc08-7bb6-42e1-a751-f0fb2c733a36"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame([dict(record.get('n')) for record in result])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ooXlcpRbFd0"
      },
      "source": [
        "Now let's grab the relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DyJ5FtBPaoDa",
        "outputId": "38edcf3b-f3a6-4ea7-d4b7-4552b51d750e"
      },
      "outputs": [],
      "source": [
        "with driver.session(database=DB_NAME) as session:\n",
        "  result = session.read_transaction(\n",
        "    lambda tx: tx.run(\n",
        "      \"\"\"\n",
        "        CALL gds.graph.streamRelationshipProperties\n",
        "        ('mygraph', ['shares', 'value'])\n",
        "        YIELD sourceNodeId, targetNodeId, relationshipType, propertyValue\n",
        "        RETURN sourceNodeId, targetNodeId, relationshipType, propertyValue\n",
        "      \"\"\"\n",
        "    ).data()\n",
        "  )\n",
        "df2 = pd.DataFrame(result)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSoFzOYOzSqH"
      },
      "source": [
        "Now we need to take that dataframe and shape it into something that better represents our classification problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "41RqFmGBzSqH",
        "outputId": "cfc38cd9-6340-463c-8924-57a2967fd3be"
      },
      "outputs": [],
      "source": [
        "x = df.pivot(index=\"nodeId\", columns=\"nodeProperty\", values=\"propertyValue\")\n",
        "x = x.reset_index()\n",
        "x.columns.name = None\n",
        "x.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPKDkUg0zSqH"
      },
      "source": [
        "Note that the embedding row is an array. To make this dataset more consumable, we should flatten that out into multiple individual features: embedding_0, embedding_1, ... embedding_n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "jaDd8a8bzSqI",
        "outputId": "e4b85746-2aa6-4731-e095-1ddb9fef4a41"
      },
      "outputs": [],
      "source": [
        "FEATURES_FILENAME = \"features.csv\"\n",
        "\n",
        "embeddings = pd.DataFrame(x[\"embedding\"].values.tolist()).add_prefix(\"embedding_\")\n",
        "merged = x.drop(columns=[\"embedding\"]).merge(embeddings, left_index=True, right_index=True)\n",
        "merged\n",
        "\n",
        "#features_df = merged.drop(columns=[\"is_fraudster\", \"num_transactions\", \"total_transaction_amnt\"])\n",
        "#train_df = merged.drop(columns=[\"nodeId\"])\n",
        "#features_df.to_csv(FEATURES_FILENAME, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeK8OgtiAC7f"
      },
      "source": [
        "Now let's write the file to Google Cloud Storage so we can use it in our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jU-jhjRjAC7f"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet google-cloud-storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azb1inEVAC7f"
      },
      "source": [
        "## Define Google Cloud variables\n",
        "You'll need to set a few variables for your GCP environment.  PROJECT_ID and STORAGE_BUCKET are most critical.  The others will probably work with the defaults given."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD1_jcA_AC7f"
      },
      "outputs": [],
      "source": [
        "# Edit these variables!\n",
        "PROJECT_ID = \"YOUR-PROJECT-ID\"\n",
        "STORAGE_BUCKET = \"YOUR-BUCKET-NAME\"\n",
        "\n",
        "# You can leave these defaults\n",
        "REGION = \"us-central1\"\n",
        "STORAGE_PATH = \"form13\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKEwR9JDAC7f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GCLOUD_PROJECT\"] = PROJECT_ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jADbBaKTAC7f"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import auth as google_auth\n",
        "    google_auth.authenticate_user()\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRKBGEi3AC7f"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "client = storage.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9Y4HhC3AC7f"
      },
      "outputs": [],
      "source": [
        "bucket = client.bucket(STORAGE_BUCKET)\n",
        "client.create_bucket(bucket)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8_owAf-AC7g"
      },
      "outputs": [],
      "source": [
        "# Upload our files to that bucket\n",
        "for filename in [FEATURES_FILENAME, TRAINING_FILENAME]:\n",
        "    upload_path = os.path.join(STORAGE_PATH, filename)\n",
        "    blob = bucket.blob(upload_path)\n",
        "    blob.upload_from_filename(filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "embedding.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
