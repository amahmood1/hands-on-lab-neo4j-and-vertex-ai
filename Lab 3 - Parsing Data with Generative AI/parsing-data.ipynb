{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ae6874-7585-4a0b-848c-965f639def41",
   "metadata": {},
   "source": [
    "# Knowledge Graph Creation with Generative AI\n",
    "\n",
    "In this notebook, let's explore how to leverage Google Generative AI to build and consume a knowledge graph in Neo4j.\n",
    "\n",
    "This notebook parses Form-13 data From SEC EAGDAR. While partially structured with XML, the formatting of these forms isn't always consistent and contains some non-standard practices.  Insead of spending our time writing a bespoke parser to extract data from these files and load into Neo4j, we will prompt a Large Language Model (LLM) to do this for us automatically.  We will then also use the LLM to generate Cypher statments to load the extracted data into a Neo4j graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbadcd3e-3306-41bf-986a-bb690b2f1a7b",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First off, check that the Python environment you installed in the readme is running this notebook. Make sure you select the py38 kernel in the top right of this notebook. You should see a 3.8 version when you run this command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a58389-bf6e-4304-bf49-3d3d06a5732b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cb3b8f-e03c-4f08-9ff4-27b21d1fc0d9",
   "metadata": {},
   "source": [
    "Next we install and import some libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aad4e36-7048-4bbf-a71a-a5d1b24d0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install --user \"google-cloud-aiplatform>=1.25.0\" --upgrade\n",
    "%pip install --user \"google-cloud-aiplatform[pipelines]>=1.25.0\"\n",
    "%pip install --user graphdatascience "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd7c539-68b5-4126-990e-60c85b84fafa",
   "metadata": {},
   "source": [
    "Now restart the kernel. That will allow the Python evironment to import the new packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e7aeea-5d5d-4cbc-a454-9708de3a3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from string import Template\n",
    "\n",
    "# Vertexai and gcloud\n",
    "import vertexai\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "from google.cloud import storage\n",
    "\n",
    "# Neo4j\n",
    "from graphdatascience import GraphDataScience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1a385-8d3a-4c69-9817-ed14ba8e6511",
   "metadata": {},
   "source": [
    "## Prompt Definition\n",
    "\n",
    "In the upcoming sections, we will extract knowledge adhering to the following schema. This is a very Simplified schema to denote investment management entities and companies they own through common stock. Normally, you will have Domain Experts who come up with a richer data model, and you can extend the below to work on more data/forms to fill such a model.\n",
    "\n",
    "![](images/12-graph-data-model.png)\n",
    "\n",
    "To achieve our Extraction goal as per the schema, We will use a series of prompts, each focused on only one task - to extract a specific entity. By this way, you can go for more granular extraction. The prompts I used here can be improved and in production scenario, you should consider running QA on the prompt pipelines to ensure that the extracted information is correct.\n",
    "\n",
    "Let's go in this order to gather the data in accordance to out data model:\n",
    "\n",
    "1. Extract Manager Information\n",
    "2. Extract Filing Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffeab081-6bc7-41a1-92a6-1f02b8adcf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr_info_tpl = \"\"\"From the text below, extract the following as json. Do not miss any of these information.\n",
    "* The tags mentioned below may or may not namespaced. So extract accordingly. Eg: <ns1:tag> is equal to <tag>\n",
    "* \"name\" - The name from the <name> tag under <filingManager> tag\n",
    "* \"street1\" - The manager's street1 address from the <com:street1> tag under <address> tag\n",
    "* \"street2\" - The manager's street2 address from the <com:street2> tag under <address> tag\n",
    "* \"city\" - The manager's city address from the <com:city> tag under <address> tag\n",
    "* \"stateOrCounty\" - The manager's stateOrCounty address from the <com:stateOrCountry> tag under <address> tag\n",
    "* \"zipCode\" - The manager's zipCode from the <com:zipCode> tag under <address> tag\n",
    "* \"reportCalendarOrQuarter\" - The reportCalendarOrQuarter from the <reportCalendarOrQuarter> tag under <address> tag\n",
    "* Just return me the JSON enclosed by 3 backticks. No other text in the response\n",
    "\n",
    "Text:\n",
    "$ctext\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2578f8a4-d816-4d78-8fd4-83f28d5b28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filing_info_tpl = \"\"\"The text below contains a list of investments. Each instance of <infoTable> tag represents a unique investment. \n",
    "For each investment, please extract the below variables into json then combine into a list enclosed by 3 back ticks. Please use the quated names below while doing this\n",
    "* \"cusip\" - The cusip from the <cusip> tag under <infoTable> tag\n",
    "* \"name\" - The name under the <nameOfIssuer> tag.\n",
    "* \"value\" - The value from the <value> tag under <infoTable> tag. Return as a number. \n",
    "* \"shares\" - The sshPrnamt from the <sshPrnamt> tag under <infoTable> tag. Return as a number. \n",
    "* \"sshPrnamtType\" - The sshPrnamtType from the <sshPrnamtType> tag under <infoTable> tag\n",
    "* \"investmentDiscretion\" - The investmentDiscretion from the <investmentDiscretion> tag under <infoTable> tag\n",
    "* \"votingSole\" - The votingSole from the <votingSole> tag under <infoTable> tag\n",
    "* \"votingShared\" - The votingShared from the <votingShared> tag under <infoTable> tag\n",
    "* \"votingNone\" - The votingNone from the <votingNone> tag under <infoTable> tag\n",
    "\n",
    "Text:\n",
    "$ctext\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481717bb-6db2-4465-8667-b0c07da381d5",
   "metadata": {},
   "source": [
    "## Functions for Using LLMs\n",
    "\n",
    "Lets creater some  helper function to talk to the LLM with our prompt and text input. We will use the text-bison base model. In your use case, you might need to tune it. VertexAI provides an elegant way to finetune it. The weights will be staying within your tenant and the base model is frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf02fcb-1cf9-4cee-897c-83c7f2ec4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, you will need to set your project_id\n",
    "project_id = 'neo4jbusinessdev'\n",
    "location = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e42db05-86be-4171-9ef3-538af376057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper for calling language model\n",
    "def run_text_model(\n",
    "    project_id: str,\n",
    "    model_name: str,\n",
    "    temperature: float,\n",
    "    max_decode_steps: int,\n",
    "    top_p: float,\n",
    "    top_k: int,\n",
    "    prompt: str,\n",
    "    location: str = location,\n",
    "    tuned_model_name: str = None,\n",
    "    ) :\n",
    "    \"\"\"Text Completion Use a Large Language Model.\"\"\"\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    if tuned_model_name is None:\n",
    "        model = TextGenerationModel.from_pretrained(model_name)\n",
    "    else:\n",
    "        model = model.get_tuned_model(tuned_model_name)\n",
    "    response = model.predict(\n",
    "        prompt,\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=max_decode_steps,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ca2aab-87a9-4628-9f17-6a8fd7d08153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper for entity extraction / parsing\n",
    "def extract_entities_relationships(prompt, tuned_model_name=None):\n",
    "    try:\n",
    "        res = run_text_model(project_id, \"text-bison@001\", 0, 1024, 0.8, 1, prompt, location, tuned_model_name)\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "726ef3e9-e66f-45ed-be59-d386ce1db4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting function for chunking up filing information to avoid hitting LLM token limits\n",
    "def split_filing_info(s, chunk_size=5):\n",
    "    pattern = '(</(\\w+:)?infoTable>)'\n",
    "    splitter = re.findall(pattern, s)[0][0]\n",
    "    _parts = s.split(splitter)\n",
    "    if len(_parts) > chunk_size:\n",
    "        chunks_of_list = np.array_split(_parts, len(_parts)/chunk_size) # max 5 filings per part\n",
    "        chunks_of_str = map(lambda x: splitter.join(x), chunks_of_list)\n",
    "        return list(chunks_of_str)\n",
    "    else:\n",
    "        return [s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb9dee8-c5dc-42ad-b05d-0f0d7e11d551",
   "metadata": {},
   "source": [
    "## Test Example for Parsing\n",
    "Lets start with one form13 file to see how we can parse it with Generative AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57cc2dfa-4947-4afc-8b2a-6cd16338029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket('neo4j-datasets')\n",
    "blob = bucket.blob('form13/raw/raw_2023-05-15_archives_edgar_data_1027451_0000919574-23-003245.txt')\n",
    "\n",
    "inp_text = blob.download_as_string().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33cda3eb-25c6-47cf-8d11-e1981766aeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SEC-DOCUMENT>0000919574-23-003245.txt : 20230515\n",
      "<SEC-HEADER>0000919574-23-003245.hdr.sgml : 20230515\n",
      "<ACCEPTANCE-DATETIME>20230515103943\n",
      "ACCESSION NUMBER:\t\t0000919574-23-003245\n",
      "CONFORMED SUBMISSION TYPE:\t13F-HR\n",
      "PUBLIC DOCUMENT COUNT:\t\t2\n",
      "CONFORMED PERIOD OF REPORT:\t20230331\n",
      "FILED AS OF DATE:\t\t20230515\n",
      "DATE AS OF CHANGE:\t\t20230515\n",
      "EFFECTIVENESS DATE:\t\t20230515\n",
      "\n",
      "FILER:\n",
      "\n",
      "\tCOMPANY DATA:\t\n",
      "\t\tCOMPANY CONFORMED NAME:\t\t\tTIGER MANAGEMENT L.L.C.\n",
      "\t\tCENTRAL INDEX KEY:\t\t\t0001027451\n",
      "\t\tIRS NUMBER:\t\t\t\t000000000\n",
      "\t\tSTATE OF INCORPORATION:\t\t\tDE\n",
      "\n",
      "\tFILING VALUES:\n",
      "\t\tFORM TYPE:\t\t13F-HR\n",
      "\t\tSEC ACT:\t\t1934 Act\n",
      "\t\tSEC FILE NUMBER:\t028-05892\n",
      "\t\tFILM NUMBER:\t\t23919492\n",
      "\n",
      "\tBUSINESS ADDRESS:\t\n",
      "\t\tSTREET 1:\t\t101 PARK AVENUE\n",
      "\t\tCITY:\t\t\tNEW YORK\n",
      "\t\tSTATE:\t\t\tNY\n",
      "\t\tZIP:\t\t\t10178\n",
      "\t\tBUSINESS PHONE:\t\t212-984-2500\n",
      "\n",
      "\tMAIL ADDRESS:\t\n",
      "\t\tSTREET 1:\t\t101 PARK AVENUE\n",
      "\t\tCITY:\t\t\tNEW YORK\n",
      "\t\tSTATE:\t\t\tNY\n",
      "\t\tZIP:\t\t\t10178\n",
      "\n",
      "\tFORMER COMPANY:\t\n",
      "\t\tFORMER CONFORMED NAME:\tTIGER MANAGEMENT LLC/NY\n",
      "\t\tDATE OF NAME CHANGE:\t20010606\n",
      "</SEC-HEADER>\n",
      "<DOCUMENT>\n",
      "<TYPE>13F-HR\n",
      "<SEQUENCE>1\n",
      "<FILENAME>primary_doc.xml\n",
      "<TEXT>\n",
      "<XML>\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<edgarSubmission xsi:schemaLocation=\"http://www.sec.gov/edgar/thirteenffiler eis_13F_Filer.xsd\" xmlns=\"http://www.sec.gov/edgar/thirteenffiler\" xmlns:ns1=\"http://www.sec.gov/edgar/common\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n",
      "  <schemaVersion>X0202</schemaVersion>\n",
      "  <headerData>\n",
      "    <submissionType>13F-HR</submissionType>\n",
      "    <filerInfo>\n",
      "      <liveTestFlag>LIVE</liveTestFlag>\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print(inp_text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b41717f-0c6e-4642-b6fd-ca327ce474cf",
   "metadata": {},
   "source": [
    "We can split data into the manager and filing info pices using the `<XML>` tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11f23c86-3274-40fd-9c97-70337d8dd535",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = inp_text.split('<XML>')\n",
    "manager_info = contents[1].split('</XML>')[0].strip()\n",
    "filing_info = contents[2].split('</XML>')[0].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21286ffa-2ff2-40cd-8eee-8b4626f32c1f",
   "metadata": {},
   "source": [
    "### Parsing Manager Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "522d7f7b-5b24-4d05-b0b6-a3d8a85dcad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize / authenticate vertex AI SDK to begin\n",
    "vertexai.init(project=project_id, location=location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed35d7c5-ef70-419b-b9c3-69c34003a75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the text below, extract the following as json. Do not miss any of these information.\n",
      "* The tags mentioned below may or may not namespaced. So extract accordingly. Eg: <ns1:tag> is equal to <tag>\n",
      "* \"name\" - The name from the <name> tag under <filingManager> tag\n",
      "* \"street1\" - The manager's street1 address from the <com:street1> tag under <address> tag\n",
      "* \"street2\" - The manager's street2 address from the <com:street2> tag under <address> tag\n",
      "* \"city\" - The manager's city address from the <com:city> tag under <address> tag\n",
      "* \"stateOrCounty\" - The manager's stateOrCounty address from the <com:stateOrCountry> tag under <address> tag\n",
      "* \"zipCode\" - The manager's zipCode from the <com:zipCode> tag under <address> tag\n",
      "* \"reportCalendarOrQuarter\" - The reportCalendarOrQuarter from the <reportCalendarOrQuarter> tag under <address> tag\n",
      "* Just return me the JSON enclosed by 3 backticks. No other text in the response\n",
      "\n",
      "Text:\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<edgarSubmission xsi:schemaLocation=\"http://www.sec.gov/edgar/thirteenffiler eis_13F_Filer.xsd\" xmlns=\"http://www.sec.gov/edgar/thirteenffiler\" xmlns:ns1=\"http://www.sec.gov/edgar/common\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n",
      "  <schemaVersion>X0202</schemaVersion>\n",
      "  <headerData>\n",
      "    <submissionType>13F-HR</submissionType>\n",
      "    <filerInfo>\n",
      "      <liveTestFlag>LIVE</liveTestFlag>\n",
      "      <flags>\n",
      "        <confirmingCopyFlag>false</confirmingCopyFlag>\n",
      "        <returnCopyFlag>false</returnCopyFlag>\n",
      "        <overrideInternetFlag>false</overrideInternetFlag>\n",
      "      </flags>\n",
      "      <filer>\n",
      "        <credentials>\n",
      "          <cik>0001027451</cik>\n",
      "          <ccc>XXXXXXXX</ccc>\n",
      "        </credentials>\n",
      "      </filer>\n",
      "      <periodOfReport>03-31-2023</periodOfReport>\n",
      "    </filerInfo>\n",
      "  </headerData>\n",
      "  <formData>\n",
      "    <coverPage>\n",
      "      <reportCalendarOrQuarter>03-31-2023</reportCalendarOrQuarter>\n",
      "      <isAmendment>false</isAmendment>\n",
      "      <filingManager>\n",
      "        <name>TIGER MANAGEMENT L.L.C.</name>\n",
      "        <address>\n",
      "          <ns1:street1>101 PARK AVENUE</ns1:street1>\n",
      "          <ns1:city>NEW YORK</ns1:city>\n",
      "          <ns1:stateOrCountry>NY</ns1:stateOrCountry>\n",
      "          <ns1:zipCode>10178</ns1:zipCode>\n",
      "        </address>\n",
      "      </filingManager>\n",
      "      <reportType>13F HOLDINGS REPORT</reportType>\n",
      "      <form13FFileNumber>028-05892</form13FFileNumber>\n",
      "      <provideInfoForInstruction5>N</provideInfoForInstruction5>\n",
      "    </coverPage>\n",
      "    <signatureBlock>\n",
      "      <name>Elouise Manhertz</name>\n",
      "      <title>Chief Financial Officer</title>\n",
      "      <phone>212-984-8869</phone>\n",
      "      <signature>/s/ Elouise Manhertz</signature>\n",
      "      <city>New York</city>\n",
      "      <stateOrCountry>NY</stateOrCountry>\n",
      "      <signatureDate>05-15-2023</signatureDate>\n",
      "    </signatureBlock>\n",
      "    <summaryPage>\n",
      "      <otherIncludedManagersCount>0</otherIncludedManagersCount>\n",
      "      <tableEntryTotal>33</tableEntryTotal>\n",
      "      <tableValueTotal>187894142</tableValueTotal>\n",
      "    </summaryPage>\n",
      "  </formData>\n",
      "</edgarSubmission>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create prompt\n",
    "prompt = Template(mgr_info_tpl).substitute(ctext=manager_info)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b13100f-de4b-49f9-89f6-58e01c19727e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'TIGER MANAGEMENT L.L.C.',\n",
       " 'street1': '101 PARK AVENUE',\n",
       " 'street2': '',\n",
       " 'city': 'NEW YORK',\n",
       " 'stateOrCounty': 'NY',\n",
       " 'zipCode': '10178',\n",
       " 'reportCalendarOrQuarter': '03-31-2023'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use LLM to parse out manager info\n",
    "manager_data = json.loads(extract_entities_relationships(prompt).split('```')[1].strip('json'))\n",
    "manager_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775186c0-d2bc-4711-88c4-0e61488ad2bd",
   "metadata": {},
   "source": [
    "### Parse Filing Information\n",
    "We will parse filing info in a similar manner to manager information. Because the filings include a list of many entries however, we will want to split the input into chunks so as not to exceed input or output token limits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aa1690a-012b-4056-8fcc-6e04e4bb26f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filing_info_chunks = split_filing_info(filing_info)\n",
    "len(filing_info_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "125ed4c0-22b9-4fc8-83f0-a1ccc5eaa112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ```\n",
      "[\n",
      "  {\n",
      "    \"cusip\": \"02079K305\",\n",
      "    \"name\": \"ALPHABET INC\",\n",
      "    \"value\": 1488692,\n",
      "    \"shares\": 14352,\n",
      "    \"sshPrnamtType\": \"SH\",\n",
      "    \"investmentDiscretion\": \"SOLE\",\n",
      "    \"votingSole\": 14352,\n",
      "    \"votingShared\": 0,\n",
      "    \"votingNone\": 0\n",
      "  },\n",
      "  {\n",
      "    \"cusip\": \"023135106\",\n",
      "    \"name\": \"AMAZON COM INC\",\n",
      "    \"value\": 582556,\n",
      "    \"shares\": 5640,\n",
      "    \"sshPrnamtType\": \"SH\",\n",
      "    \"investmentDiscretion\": \"SOLE\",\n",
      "    \"votingSole\": 5640,\n",
      "    \"votingShared\": 0,\n",
      "    \"votingNone\": 0\n",
      "  },\n",
      "  {\n",
      "    \"cusip\": \"049468101\",\n",
      "    \"name\": \"ATLASSIAN CORPORATION\",\n",
      "    \"value\": 205404,\n",
      "    \"shares\": 1200,\n",
      "    \"sshPrnamtType\": \"SH\",\n",
      "    \"investmentDiscretion\": \"SOLE\",\n",
      "    \"votingSole\": 1200,\n",
      "    \"votingShared\": 0,\n",
      "    \"votingNone\": 0\n",
      "  },\n",
      "  {\n",
      "    \"cusip\": \"053332102\",\n",
      "    \"name\": \"AUTOZONE INC\",\n",
      "    \"value\": 9218063,\n",
      "    \"shares\": 3750,\n",
      "    \"sshPrnamtType\": \"SH\",\n",
      "    \"investmentDiscretion\": \"SOLE\",\n",
      "    \"votingSole\": 3750,\n",
      "    \"votingShared\": 0,\n",
      "    \"votingNone\": 0\n",
      "  },\n",
      "  {\n",
      "    \"cusip\": \"19260Q107\",\n",
      "    \"name\": \"COINBASE GLOBAL INC\",\n",
      "    \"value\": 1086458,\n",
      "    \"shares\": 16079,\n",
      "    \"sshPrnamtType\": \"SH\",\n",
      "    \"investmentDiscretion\": \"SOLE\",\n",
      "    \"votingSole\": 16079,\n",
      "    \"votingShared\": 0,\n",
      "    \"votingNone\": 0\n",
      "  },\n",
      "  {\n",
      "    \"cusip\": \"247361702\",\n",
      "    \"name\": \"DELTA AIR LINES INC DEL\",\n",
      "    \"value\": 7008444,\n",
      "    \"shares\": 200700,\n",
      "    \"sshPrnamtType\": \"SH\",\n",
      "    \"investmentDiscretion\": \"SOLE\",\n",
      "    \"votingSole\": 200700,\n",
      "    \"votingShared\": 0,\n",
      "    \"votingNone\": 0\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = Template(filing_info_tpl).substitute(ctext=filing_info_chunks[0])\n",
    "response = extract_entities_relationships(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba6eb5-9995-42d8-bf3c-0e6cb09b1536",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a2560b-2e6c-4b96-abc3-7c96196d0eb5",
   "metadata": {},
   "source": [
    "### Test Example\n",
    "\n",
    "Lets walk through the steps to do this with just the 1 form above first, then we can move on to parsing and ingesting all the form13s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a67de-b18f-4c65-a529-b890086663b8",
   "metadata": {},
   "source": [
    "To start we can run the LLM parsing over all the filing info from the form then combine the resulting json into a list condusive for Neo4j loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "827621eb-2f7d-4ef4-9f00-cddbc5e2cfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cusip': '02079K305',\n",
       "  'name': 'ALPHABET INC',\n",
       "  'value': 1488692,\n",
       "  'shares': 14352,\n",
       "  'sshPrnamtType': 'SH',\n",
       "  'investmentDiscretion': 'SOLE',\n",
       "  'votingSole': 14352,\n",
       "  'votingShared': 0,\n",
       "  'votingNone': 0,\n",
       "  'managerName': 'TIGER MANAGEMENT L.L.C.',\n",
       "  'reportCalendarOrQuarter': '03-31-2023'},\n",
       " {'cusip': '023135106',\n",
       "  'name': 'AMAZON COM INC',\n",
       "  'value': 582556,\n",
       "  'shares': 5640,\n",
       "  'sshPrnamtType': 'SH',\n",
       "  'investmentDiscretion': 'SOLE',\n",
       "  'votingSole': 5640,\n",
       "  'votingShared': 0,\n",
       "  'votingNone': 0,\n",
       "  'managerName': 'TIGER MANAGEMENT L.L.C.',\n",
       "  'reportCalendarOrQuarter': '03-31-2023'},\n",
       " {'cusip': '049468101',\n",
       "  'name': 'ATLASSIAN CORPORATION',\n",
       "  'value': 205404,\n",
       "  'shares': 1200,\n",
       "  'sshPrnamtType': 'SH',\n",
       "  'investmentDiscretion': 'SOLE',\n",
       "  'votingSole': 1200,\n",
       "  'votingShared': 0,\n",
       "  'votingNone': 0,\n",
       "  'managerName': 'TIGER MANAGEMENT L.L.C.',\n",
       "  'reportCalendarOrQuarter': '03-31-2023'},\n",
       " {'cusip': '053332102',\n",
       "  'name': 'AUTOZONE INC',\n",
       "  'value': 9218063,\n",
       "  'shares': 3750,\n",
       "  'sshPrnamtType': 'SH',\n",
       "  'investmentDiscretion': 'SOLE',\n",
       "  'votingSole': 3750,\n",
       "  'votingShared': 0,\n",
       "  'votingNone': 0,\n",
       "  'managerName': 'TIGER MANAGEMENT L.L.C.',\n",
       "  'reportCalendarOrQuarter': '03-31-2023'},\n",
       " {'cusip': '19260Q107',\n",
       "  'name': 'COINBASE GLOBAL INC',\n",
       "  'value': 1086458,\n",
       "  'shares': 16079,\n",
       "  'sshPrnamtType': 'SH',\n",
       "  'investmentDiscretion': 'SOLE',\n",
       "  'votingSole': 16079,\n",
       "  'votingShared': 0,\n",
       "  'votingNone': 0,\n",
       "  'managerName': 'TIGER MANAGEMENT L.L.C.',\n",
       "  'reportCalendarOrQuarter': '03-31-2023'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filings_list = []\n",
    "for filing_info_chunk in filing_info_chunks:\n",
    "    prompt = Template(filing_info_tpl).substitute(ctext=filing_info_chunk)\n",
    "    response = extract_entities_relationships(prompt)\n",
    "    filings_list.extend(json.loads(response.replace('```', '')))\n",
    "\n",
    "for item in filings_list:\n",
    "    item['managerName'] = manager_data['name']\n",
    "    item['reportCalendarOrQuarter'] = manager_data['reportCalendarOrQuarter']\n",
    "filings_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09f6b661-7d08-42fa-9dda-6ea9e8dfcffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filings_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b83ca6-c44b-4f43-9dcd-c88cf525a978",
   "metadata": {},
   "source": [
    "#### Establish Neo4j Connection\n",
    "We will assume you are using AuraDS here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93fffd14-e6bb-4843-90e9-d1d4e7cef3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# username is neo4j by default\n",
    "NEO4J_USERNAME = 'neo4j'\n",
    "# You will need to change these to match\n",
    "NEO4J_URI = '<neo4j+s://xxxxx.databases.neo4j.io>'\n",
    "NEO4J_PASSWORD = '<password>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f38e2ef1-f5bd-4561-87e7-a014b8af2e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "gds = GraphDataScience(\n",
    "    NEO4J_URI,\n",
    "    auth=(NEO4J_USERNAME, NEO4J_PASSWORD),\n",
    "    aura_ds=True\n",
    ")\n",
    "gds.set_database('neo4j')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f6adf6-a299-47ca-a965-6b6cdec67f77",
   "metadata": {},
   "source": [
    "Before loading we should create uniquenss constraints for nodes.  This acts as a unique id and an index and is necessary for fast, efficient, queries.  In general, if you notice ingestion is super slow (and getting slower) with Neo4j, double check that you created indexes.  For this small sample it won't matter, but it will certainly imact as we ingest more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3084e75-da30-42c1-8ca4-10cf55e7c3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.run_cypher('CREATE CONSTRAINT unique_manager IF NOT EXISTS FOR (n:Manager) REQUIRE (n.name) IS UNIQUE')\n",
    "gds.run_cypher('CREATE CONSTRAINT unique_company_id IF NOT EXISTS FOR (n:Company) REQUIRE (n.cusip) IS UNIQUE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814834e0-54f6-4e6f-9a6e-67a526cf3bf6",
   "metadata": {},
   "source": [
    "To Merge in the data we can use paramterized cypher queries.  Basically we are going to send filings in batches (in this sample case just one batch) for each node and relationship type and insert them as parameters in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "feb25f22-39a0-4930-bf05-8adaa45c2f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_node_merge_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_node_merge_count\n",
       "0                        33"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Company Nodes.\n",
    "gds.run_cypher('''\n",
    "UNWIND $records AS record\n",
    "MERGE (c:Company {cusip: record.cusip})\n",
    "SET c.name = record.name\n",
    "RETURN count(c) AS company_node_merge_count\n",
    "''', params={'records':filings_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "635b9393-a2b6-4da6-94a4-cca6bcf515bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Manager Node. In this case we just have one\n",
    "gds.run_cypher('''\n",
    "MERGE (m:Manager {name: $name})\n",
    "''', params={'name':manager_data['name']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5394e270-45c3-44c9-96bb-6ea210dbb28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owns_relationship_merge_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   owns_relationship_merge_count\n",
       "0                             33"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge OWNS Relationship\n",
    "gds.run_cypher('''\n",
    "UNWIND $records AS record\n",
    "MATCH (m:Manager {name: record.managerName})\n",
    "MATCH (c:Company {cusip: record.cusip})\n",
    "MERGE(m)-[r:OWNS]->(c)\n",
    "SET r.reportCalendarOrQuarter = record.reportCalendarOrQuarter,\n",
    "    r.value = record.value,\n",
    "    r.shares = record.shares\n",
    "RETURN count(r) AS owns_relationship_merge_count\n",
    "''', params={'records':filings_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16dea42-4efc-4f13-9ccd-933b7c85b190",
   "metadata": {},
   "source": [
    "You can now check the graph to see the loaded sample data\n",
    "\n",
    "![](images/13-sample-graph-snapshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7ebde6-7e39-40fc-8457-4d39bb45efd1",
   "metadata": {},
   "source": [
    "### Ingest Multiple Form 13 Files\n",
    "We will make a pipeline using the methods above.  In this case we will take a two-step approach, first parse all the data, then chunk that data and ingest into Neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc184c25-ad3f-4fd7-bae3-984643e80b7e",
   "metadata": {},
   "source": [
    "To start, lets take a look at all the form13 samples we have in cloud storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbd46151-2c82-47de-91c0-3643e7271a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44142 total raw form13 files\n"
     ]
    }
   ],
   "source": [
    "blobs = storage_client.list_blobs('neo4j-datasets', prefix='form13/raw/', delimiter='/')\n",
    "file_names = [blob.name for blob in blobs if '.txt' in blob.name]\n",
    "print(f'{len(file_names)} total raw form13 files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a0900b-0312-4213-9a3d-13e512226f93",
   "metadata": {},
   "source": [
    "For purposes of this module we will just use the first 5 in this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29c1d593-dd40-4f08-ac0d-9c8e9ff201d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['form13/raw/raw_2022-01-03_archives_edgar_data_1026200_0001567619-22-000057.txt',\n",
       " 'form13/raw/raw_2022-01-03_archives_edgar_data_1315339_0001315339-22-000001.txt',\n",
       " 'form13/raw/raw_2022-01-03_archives_edgar_data_1384943_0001384943-22-000001.txt',\n",
       " 'form13/raw/raw_2022-01-03_archives_edgar_data_1452208_0001104659-22-000174.txt',\n",
       " 'form13/raw/raw_2022-01-03_archives_edgar_data_1624809_0001624809-22-000001.txt']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_file_names = file_names[:5]\n",
    "sample_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "568c27a4-d6bf-4e12-af6e-478e20fe5ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for getting filing info\n",
    "def get_manager_and_filing_info(raw_txt):\n",
    "    contents = raw_txt.split('<XML>')\n",
    "    manager_info = contents[1].split('</XML>')[0].strip()\n",
    "    filing_info = contents[2].split('</XML>')[0].strip()\n",
    "    \n",
    "    return manager_info, filing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d46cc84-53b5-4088-a5aa-578f7eb5d0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Parsing 5 Form 13 Files ===\n",
      "--- parsing form13/raw/raw_2022-01-03_archives_edgar_data_1026200_0001567619-22-000057.txt ---\n",
      "getting file text from gcloud....\n",
      "getting file contents...\n",
      "Parsing submission and manager info...\n",
      "Parsing filing info...\n",
      "--- parsing form13/raw/raw_2022-01-03_archives_edgar_data_1315339_0001315339-22-000001.txt ---\n",
      "getting file text from gcloud....\n",
      "getting file contents...\n",
      "Parsing submission and manager info...\n",
      "Parsing filing info...\n",
      "--- parsing form13/raw/raw_2022-01-03_archives_edgar_data_1384943_0001384943-22-000001.txt ---\n",
      "getting file text from gcloud....\n",
      "getting file contents...\n",
      "Parsing submission and manager info...\n",
      "Parsing filing info...\n",
      "--- parsing form13/raw/raw_2022-01-03_archives_edgar_data_1452208_0001104659-22-000174.txt ---\n",
      "getting file text from gcloud....\n",
      "getting file contents...\n",
      "Parsing submission and manager info...\n",
      "Parsing filing info...\n",
      "--- parsing form13/raw/raw_2022-01-03_archives_edgar_data_1624809_0001624809-22-000001.txt ---\n",
      "getting file text from gcloud....\n",
      "getting file contents...\n",
      "Parsing submission and manager info...\n",
      "Parsing filing info...\n",
      "CPU times: user 536 ms, sys: 181 ms, total: 717 ms\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "print(f'=== Parsing {len(sample_file_names)} Form 13 Files ===')\n",
    "\n",
    "filings_list = []\n",
    "manager_list = []\n",
    "\n",
    "for file_name in sample_file_names:\n",
    "    \n",
    "    print(f'--- parsing {file_name} ---')\n",
    "    try:\n",
    "        #Get raw form13 file\n",
    "        print('getting file text from gcloud....')\n",
    "        blob = bucket.blob(file_name)\n",
    "        raw_text = blob.download_as_string().decode()\n",
    "\n",
    "        #Get raw manager and filing info from file\n",
    "        print('getting file contents...')\n",
    "        manager_info, filing_info = get_manager_and_filing_info(raw_text)\n",
    "\n",
    "        #Parse manager info into dict using LLM\n",
    "        print('Parsing submission and manager info...')\n",
    "        mng_prompt = Template(mgr_info_tpl).substitute(ctext=manager_info)\n",
    "        mng_response = extract_entities_relationships(mng_prompt)\n",
    "        manager_data = json.loads(mng_response.replace('```', ''))\n",
    "        manager_list.append({'name': manager_data['name']})\n",
    "\n",
    "        #Parse filing info into list of dicts using LLM\n",
    "        print('Parsing filing info...')\n",
    "        for filing_info_chunk in filing_info_chunks:\n",
    "            filing_prompt = Template(filing_info_tpl).substitute(ctext=filing_info_chunk)\n",
    "            filing_response = extract_entities_relationships(filing_prompt)\n",
    "            filings_list.extend(json.loads(filing_response.replace('```', '')))\n",
    "        for item in filings_list: #Add information from manager_info to enable OWNS relationship loading\n",
    "            item['managerName'] = manager_data['name']\n",
    "            item['reportCalendarOrQuarter'] = manager_data['reportCalendarOrQuarter']\n",
    "    except Exception as e:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df9206bb-d619-4649-99cf-f5939461555a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manager_node_merge_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   manager_node_merge_count\n",
       "0                         5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Manager Nodes.\n",
    "gds.run_cypher('''\n",
    "UNWIND $records AS record\n",
    "MERGE (m:Manager {name: record.name})\n",
    "RETURN count(m) AS manager_node_merge_count\n",
    "''', params={'records':manager_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c31f300-1c53-4795-ae1c-7228f240ddf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ceb716e1-c71c-4992-b654-016f9496f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at the dataset gets bigger we will want to chunk up the filings we send to Neo4j\n",
    "def chunks(xs, n=10_000):\n",
    "    n = max(1, n)\n",
    "    return [xs[i:i + n] for i in range(0, len(xs), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2216015-d8ca-475d-8240-a5717081c8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   company_node_merge_count\n",
      "0                       165\n"
     ]
    }
   ],
   "source": [
    "# Merge Company Nodes\n",
    "for d in chunks(filings_list):\n",
    "    res = gds.run_cypher('''\n",
    "    UNWIND $records AS record\n",
    "    MERGE (c:Company {cusip: record.cusip})\n",
    "    SET c.name = record.name\n",
    "    RETURN count(c) AS company_node_merge_count\n",
    "    ''', params={'records':d})\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "750215eb-ec16-4b42-909f-cf763b9955b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   owns_relationship_merge_count\n",
      "0                            165\n"
     ]
    }
   ],
   "source": [
    "# Merge OWNS Relationships\n",
    "for d in chunks(filings_list):\n",
    "    res = gds.run_cypher('''\n",
    "    UNWIND $records AS record\n",
    "    MATCH (m:Manager {name: record.managerName})\n",
    "    MATCH (c:Company {cusip: record.cusip})\n",
    "    MERGE(m)-[r:OWNS]->(c)\n",
    "    SET r.reportCalendarOrQuarter = record.reportCalendarOrQuarter,\n",
    "        r.value = record.value,\n",
    "        r.shares = record.shares\n",
    "    RETURN count(r) AS owns_relationship_merge_count\n",
    "    ''', params={'records':d})\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15743a-0125-4493-a9aa-cb914668d336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de406be2-6bea-4775-8c2f-0176a6f5e737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
