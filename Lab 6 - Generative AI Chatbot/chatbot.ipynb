{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d8979e",
   "metadata": {},
   "source": [
    "# Chatbot\n",
    "In this notebook, let's explore how to leverage Google GenAI to consume from a knowledge graph in Neo4j.\n",
    "\n",
    "This notebook queries an SEC investment graph database using Google Vertex AI Generative AI's `code-bison` model.   We will prompt this model  to convert questions in English to Cypher - Neo4j's query language, which can be used for data retrieval.  It uses the LangChain library in Python to combine the steps for generating queries, executing the queries, and folding the query result sets into a natural language response into one smooth sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e9561",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4bf94c",
   "metadata": {},
   "source": [
    "First, check to make sure you're using the Python 3.8 runtime with the following command. If you see a different runtime, try changing the kernel to `py38` in the upper right corner of the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14563980-d21f-46fb-81d2-934c57c5f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f97aa",
   "metadata": {},
   "source": [
    "If that checks out, run the below cell to install the libraries. We are installing libraries both for the agent integration and the chatbot interface here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12836e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --user graphdatascience --upgrade  # Neo4j's GDS client library\n",
    "%pip install --user langchain  # library for combining functional steps around LLM calls\n",
    "%pip install --user google-cloud-aiplatform  # library for accessing VertexAI\n",
    "%pip install --user neo4j --upgrade  # official Neo4j python library\n",
    "%pip install --user pydantic\n",
    "%pip install --user gradio  # for building the chat interface\n",
    "%pip install --user IProgress\n",
    "%pip install --user tqdm\n",
    "%pip install --user typing_extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b72ba",
   "metadata": {},
   "source": [
    "When this succeeds, you probably need to restart the notebook kernel. Click on `Kernel` > `Restart Kernel...` in the file menu on top of the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba716344",
   "metadata": {},
   "source": [
    "### Neo4j setup\n",
    "\n",
    "Import your Neo4j libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fed1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "import neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66325ba5",
   "metadata": {},
   "source": [
    "Provide your Neo4j credentials.  We need the DB conection URL, the username (probably `neo4j`), and your password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#database credentials\n",
    "NEO4J_URI=\"neo4j+s://92cb3ca9.databases.neo4j.io\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"3GFvjeqkQXLHWJgqIvjNlmbwdZXD5Dgjj1hmPZB0Pgg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a796c",
   "metadata": {},
   "source": [
    "Initialize your GDS client connection as below.  We can run queries or algorithms from the `gds` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "gds = GraphDataScience(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2050e4da",
   "metadata": {},
   "source": [
    "### LangChain setup\n",
    "\n",
    "We will import the relevant submodules from `langchain`.  We are bringing in a Neo4j Question/Answer component, and component for connecting LangChain to the Neo4j graph to be queried, the VertexAI LLM object, and a utility for creating prompt templates that will aid in Cypher query generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a76b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import GraphCypherQAChain, LLMChain\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bab5ba-8575-4020-b86b-f0ab54f1806d",
   "metadata": {},
   "source": [
    "### Entrypoint Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9106388e-ad8d-45c0-a75d-1286c24ac0c9",
   "metadata": {},
   "source": [
    "We can put a procedural step in front of our chatbot to help us handle non-relevant responses, which will cause Cypher syntax errors to be thrown otherwise.  We will use the `text-bison` model for this step, and we will give it a simple prompt that instructs it to decide if a question coming in is relevant to the database.  If so, it can be passed through to the Cypher generation chain.  If not, the agent can simply issue and answer and we never have to try to generate Cypher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8776e8-7d56-4c6b-aba0-6ee8ebc5e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrypoint_prompt_template = \"\"\"\n",
    "\n",
    "You are an entrypoint for a finance/investment database.  If your prompt is not related to finance, investments, companies, \n",
    "or similar topics, try to answer the prompt if you can in chat style and remind the user that you are a chatbot for accessing a\n",
    "finance database.  If it is about those topics, return True as your entire answer.\n",
    "\n",
    "The next text is the user prompt:\n",
    "\n",
    "{prompt}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "agent_llm = VertexAI(model_name=\"text-bison\", temperature=0)\n",
    "entrypoint = LLMChain(\n",
    "    llm=agent_llm,\n",
    "    prompt=PromptTemplate.from_template(entrypoint_prompt_template)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f48b3-b499-4f0a-b6d3-43d782214b37",
   "metadata": {},
   "source": [
    "We'll combine these elements into a function that will handle this initial query test.  This can be called later in the chatbot code before we hit the Cypher generation chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3182cb24-6783-4248-b2c7-95332734e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrypoint_agent(nl_query):\n",
    "    agent_response = entrypoint(nl_query)\n",
    "    return {\n",
    "        \"query\": nl_query,\n",
    "        \"response\": agent_response[\"text\"],\n",
    "        \"is_relevant\": agent_response[\"text\"] == \"True\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e6e37b-9cac-42db-85fe-3c8df9860018",
   "metadata": {},
   "source": [
    "We can test a few examples of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2993400-f4eb-4848-b8db-f4396516d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1.\")\n",
    "print(entrypoint_agent(\"Hello, how are you doing?\"))\n",
    "print(\"\\n2.\")\n",
    "print(entrypoint_agent(\"What is the average temperature of the surface of the sun?\"))\n",
    "print(\"\\n3.\")\n",
    "print(entrypoint_agent(\"Can you tell me which investors had the best year in 2022?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044359a",
   "metadata": {},
   "source": [
    "## Cypher Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acd6ec8",
   "metadata": {},
   "source": [
    "We have to use a prompt template that clearly states what schema to use, the principles that the chatbot should follow in generating responses, and some few-shot examples to help the chatbot be more accurate in its query generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23987ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt/template \n",
    "CYPHER_GENERATION_TEMPLATE = \"\"\"You are an expert Neo4j Cypher translator who understands the question in english and convert to Cypher strictly based on the Neo4j Schema provided and following the instructions below:\n",
    "1. Generate Cypher query compatible ONLY for Neo4j Version 5\n",
    "2. Do not use EXISTS, SIZE keywords in the cypher. Use alias when using the WITH keyword\n",
    "3. Please do not use same variable names for different nodes and relationships in the query.\n",
    "4. Use only Nodes and relationships mentioned in the schema\n",
    "5. Always enclose the Cypher output inside 3 backticks\n",
    "6. Always do a case-insensitive and fuzzy search for any properties related search. Eg: to search for a Company name use `toLower(c.name) contains 'neo4j'`\n",
    "7. Candidate node is synonymous to Manager\n",
    "8. Always use aliases to refer the node in the query\n",
    "9. 'Answer' is NOT a Cypher keyword. Answer should never be used in a query.\n",
    "10. Please generate only one Cypher query per question. \n",
    "11. Cypher is NOT SQL. So, do not mix and match the syntaxes.\n",
    "12. Every Cypher query always starts with a MATCH keyword.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "Samples:\n",
    "Question: Which fund manager owns most shares? What is the total portfolio value?\n",
    "Answer: MATCH (m:Manager) -[o:OWNS]-> (c:Company) RETURN m.managerName as manager, sum(distinct o.shares) as ownedShares, sum(o.value) as portfolioValue ORDER BY ownedShares DESC LIMIT 10\n",
    "\n",
    "Question: Which fund manager owns most companies? How many shares?\n",
    "Answer: MATCH (m:Manager) -[o:OWNS]-> (c:Company) RETURN m.managerName as manager, count(distinct c) as ownedCompanies, sum(distinct o.shares) as ownedShares ORDER BY ownedCompanies DESC LIMIT 10\n",
    "\n",
    "Question: What are the top 10 investments for Vanguard?\n",
    "Answer: MATCH (m:Manager) -[o:OWNS]-> (c:Company) WHERE toLower(m.managerName) contains \"vanguard\" RETURN c.companyName as Investment, sum(DISTINCT o.shares) as totalShares, sum(DISTINCT o.value) as investmentValue order by investmentValue desc limit 10\n",
    "\n",
    "Question: What other fund managers are investing in same companies as Vanguard?\n",
    "Answer: MATCH (m1:Manager) -[:OWNS]-> (c1:Company) <-[o:OWNS]- (m2:Manager) WHERE toLower(m1.managerName) contains \"vanguard\" AND elementId(m1) <> elementId(m2) RETURN m2.managerName as manager, sum(DISTINCT o.shares) as investedShares, sum(DISTINCT o.value) as investmentValue ORDER BY investmentValue LIMIT 10\n",
    "\n",
    "Question: What are the top investors for Apple?\n",
    "Answer: MATCH (m1:Manager) -[o:OWNS]-> (c1:Company) WHERE toLower(c1.companyName) contains \"apple\" RETURN distinct m1.managerName as manager, sum(o.value) as totalInvested ORDER BY totalInvested DESC LIMIT 10\n",
    "\n",
    "Question: What are the other top investments for fund managers investing in Apple?\n",
    "Answer: MATCH (c1:Company) <-[:OWNS]- (m1:Manager) -[o:OWNS]-> (c2:Company) WHERE toLower(c1.companyName) contains \"apple\" AND elementId(c1) <> elementId(c2) RETURN DISTINCT c2.companyName as company, sum(o.value) as totalInvested, sum(o.shares) as totalShares ORDER BY totalInvested DESC LIMIT 10\n",
    "\n",
    "Question: What are the top investors in the last 3 months?\n",
    "Answer: MATCH (m:Manager) -[o:OWNS]-> (c:Company) WHERE date() > o.reportCalendarOrQuarter > o.reportCalendarOrQuarter - duration({{months:3}}) RETURN distinct m.managerName as manager, sum(o.value) as totalInvested, sum(o.shares) as totalShares ORDER BY totalInvested DESC LIMIT 10\n",
    "\n",
    "Question: What are top investments in last 6 months for Vanguard?\n",
    "Answer: MATCH (m:Manager) -[o:OWNS]-> (c:Company) WHERE toLower(m.managerName) contains \"vanguard\" AND date() > o.reportCalendarOrQuarter > date() - duration({{months:6}}) RETURN distinct c.companyName as company, sum(o.value) as totalInvested, sum(o.shares) as totalShares ORDER BY totalInvested DESC LIMIT 10\n",
    "\n",
    "Question: Who are Apple's top investors in last 3 months?\n",
    "Answer: MATCH (m:Manager) -[o:OWNS]-> (c:Company) WHERE toLower(c.companyName) contains \"apple\" AND date() > o.reportCalendarOrQuarter > date() - duration({{months:3}}) RETURN distinct m.managerName as investor, sum(o.value) as totalInvested, sum(o.shares) as totalShares ORDER BY totalInvested DESC LIMIT 10\n",
    "\n",
    "Question: Which fund manager under 200 million has similar investment strategy as Vanguard?\n",
    "Answer: MATCH (m1:Manager) -[o1:OWNS]-> (:Company) <-[o2:OWNS]- (m2:Manager) WHERE toLower(m1.managerName) CONTAINS \"vanguard\" AND elementId(m1) <> elementId(m2) WITH distinct m2 AS m2, sum(distinct o2.value) AS totalVal WHERE totalVal < 200000000 RETURN m2.managerName AS manager, totalVal*0.000001 AS totalVal ORDER BY totalVal DESC LIMIT 10\n",
    "\n",
    "Question: Who are common investors in Apple and Amazon?\n",
    "Answer: MATCH (c1:Company) <-[:OWNS]- (m:Manager) -[:OWNS]-> (c2:Company) WHERE toLower(c1.companyName) contains \"apple\" AND toLower(c2.companyName) CONTAINS \"amazon\" RETURN DISTINCT m.managerName LIMIT 50\n",
    "\n",
    "Question: What are Vanguard's top investments by shares for 2023?\n",
    "Answer: MATCH (m:Manager) -[o:OWNS]-> (c:Company) WHERE toLower(m.managerName) CONTAINS \"vanguard\" AND date({{year:2023}}) = date.truncate('year',o.reportCalendarOrQuarter) RETURN c.companyName AS investment, sum(o.value) AS totalValue ORDER BY totalValue DESC LIMIT 10\n",
    "\n",
    "Question: What are Vanguard's top investments by value for 2023?\n",
    "Answer: MATCH (m:Manager) -[o:OWNS]-> (c:Company) WHERE toLower(m.managerName) CONTAINS \"vanguard\" AND date({{year:2023}}) = date.truncate('year',o.reportCalendarOrQuarter) RETURN c.companyName AS investment, sum(o.shares) AS totalShares ORDER BY totalShares DESC LIMIT 10\n",
    "\n",
    "Question: {question}\n",
    "Answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e46b3",
   "metadata": {},
   "source": [
    "Create a LangChain prompt template.  This defines the inputs that will be included as parameters into the prompt sent to the Cypher generation bot.  In our example, the inputs will be `schema` and `question`.  The question comes from the end user.  The schema is automatically inserted by the LangChain `GraphCypherQAChain` via a built in method to `Neo4jGraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86addda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"schema\",\"question\"], validate_template=True, template=CYPHER_GENERATION_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e2e7d",
   "metadata": {},
   "source": [
    "We need to connect to the graph via LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc48f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph object from Langchain\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI, \n",
    "    username=NEO4J_USERNAME, \n",
    "    password=NEO4J_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1263e2",
   "metadata": {},
   "source": [
    "We are defining our `chain` object, which combines Neo4j Q/A and VertexAI's `code-bison` LLM.  When the user gives a query, it first goes through `GraphCypherQAChain`, which generates a Cypher query according to the rules laid out in our prompt above.  That result set then goes to the `VertexAI` step of the chain, where the LLM is given the Neo4j result set and instructed to roll it into a natural language response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec96b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the chain from VertexAI langchain object\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    VertexAI(model_name='code-bison',\n",
    "            max_output_tokens=2048,\n",
    "            temperature=0,\n",
    "            top_p=0.95,\n",
    "            top_k=0.40), graph=graph, verbose=True,\n",
    "            cypher_prompt=CYPHER_GENERATION_PROMPT,\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d1590f",
   "metadata": {},
   "source": [
    "Below we have a few examples of how we can get answers from the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e6bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = chain(\"\"\"What are the top 10 investments for Blackrock?\"\"\")\n",
    "print(f\"Final answer: {r2['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a980deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r3 = chain(\"\"\"What are other top investments for fund managers investing in AstraZeneca?\"\"\")\n",
    "print(f\"Final answer: {r3['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877ae99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r4 = chain(\"\"\"Which fund manager under 200 million has similar investment strategy as Blackrock\"\"\")\n",
    "print(f\"Final answer: {r4['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588955da",
   "metadata": {},
   "outputs": [],
   "source": [
    "r5 = chain(\"\"\"Please get me 10 common investors between Tesla and Microsoft\"\"\")\n",
    "print(f\"Final answer: {r5['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "r6 = chain(\"\"\"Which managers own FAANG stocks?\"\"\")\n",
    "print(f\"Final answer: {r6['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b038e",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c246c",
   "metadata": {},
   "source": [
    "Now we are going to use Gradio to deploy a chat interface that will have our chain behind it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b608a",
   "metadata": {},
   "source": [
    "When we run the code below, a Gradio application will be deployed and can be accessed at a local URL.  We also get a public URL that can be shared for 3 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import typing_extensions\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages = True)\n",
    "llm = VertexAI(model_name='code-bison',\n",
    "            max_output_tokens=2048,\n",
    "            temperature=0,\n",
    "            top_p=0.95,\n",
    "            top_k=0.40)\n",
    "agent_chain = chain\n",
    "\n",
    "def chat_response(input_text,history):\n",
    "    try:\n",
    "        entry_response = entrypoint_agent(input_text)\n",
    "        if entry_response['is_relevant']:\n",
    "            return agent_chain.run(input_text)\n",
    "        else:\n",
    "            return entry_response[\"response\"]\n",
    "    except:\n",
    "        # a bit of protection against exposed error messages\n",
    "        # we could log these situations in the backend to revisit later in development\n",
    "        return \"I'm sorry, there was an error retrieving the information you requested.\"\n",
    "\n",
    "interface = gr.ChatInterface(fn = chat_response,\n",
    "                             title = \"Investment Chatbot\",\n",
    "                             description = \"powered by Neo4j\",\n",
    "                             theme = \"soft\",\n",
    "                             chatbot = gr.Chatbot(height=500),\n",
    "                             undo_btn = None,\n",
    "                             clear_btn = \"\\U0001F5D1 Clear chat\",\n",
    "                             examples = [\"Who are Tesla's top investors in last 3 months?\",\n",
    "                                         \"What are the top 10 investments for Blackrock?\",\n",
    "                                         \"Which manager owns FAANG stocks?\",\n",
    "                                         \"What are other top investments for fund managers investing in Exxon?\",\n",
    "                                         \"What are Vanguard's top investments by value for 2023?\",\n",
    "                                         \"Who are the common investors between Tesla and Microsoft?\"])\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5197afd",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92158fb",
   "metadata": {},
   "source": [
    "In this notebook, we went through the steps of connecting a LangChain agent to a Neo4j database and using it to generate Cypher queries in response to user requests via LLMs on VertexAI.\n",
    "\n",
    "We used the `code-bison` model, but this approach can be generalized to any of the VertexAI LLMs and it can also be augmented with additional procedural steps around the generation chain to customize the user experience further for specific use cases.  The critical takeaway is the importance of Neo4j as a grounding database to anchor your chatbot to reality as it generates responses and to enable it to provide responses enriched with relevant enterprise data.  Knowledge graph is the best type of data structure to use for this type of grounding.  We also added an entrypoint agent to help provide a more acceptable user experience in cases where the input queries from users don't match the expected subject matter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38 (Local)",
   "language": "python",
   "name": "local-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
