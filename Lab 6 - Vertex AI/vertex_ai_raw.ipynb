{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neo4j-partners/hands-on-lab-neo4j-and-vertex-ai/blob/main/Lab%206%20-%20Vertex%20AI/vertex_ai_raw.ipynb\" target=\"_blank\">\n",
        "  <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKipBL0kWY7w"
      },
      "source": [
        "# Install Additional Packages\n",
        "First off, you'll also need to install a few packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDipS8p-27qg"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet google-cloud-storage\n",
        "!pip install --quiet google.cloud.aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBXAh7fVt9Ou"
      },
      "source": [
        "# Restart the Kernel\n",
        "After you install the additional packages, you need to restart the notebook kernel so it can find the packages.  When you run this, you may get a notification that the kernel crashed.  You can disregard that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySSyV4T_3dQB"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRLomQ5ekAkE"
      },
      "source": [
        "# Split the Data\n",
        "Now let's grab the data set and split it into a training and a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHgXinwclEH2"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/neo4j-datasets/form13/form13.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9q4g_U1plOK2"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "df = pandas.read_csv('form13.csv')\n",
        "\n",
        "train = df.loc[df['reportCalendarOrQuarter'] == '03-31-2021']\n",
        "train = train.append(df.loc[df['reportCalendarOrQuarter'] == '06-30-2021'])\n",
        "train.to_csv('train.csv', index=False)\n",
        "\n",
        "test = df.loc[df['reportCalendarOrQuarter'] == '09-30-2021']\n",
        "test.to_csv('test.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id6tjQDbgf2S"
      },
      "source": [
        "# Authenticate your Google Cloud Account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvZqoRzdlu6m"
      },
      "outputs": [],
      "source": [
        "# Edit these variables!\n",
        "PROJECT_ID = 'YOUR-PROJECT-ID'\n",
        "STORAGE_BUCKET = 'NAME-OF-BUCKET-FROM-PREVIOUS-LAB'\n",
        "\n",
        "# You can leave these defaults\n",
        "REGION = 'us-central1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XoT1nT_JlYx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GCLOUD_PROJECT'] = PROJECT_ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HucMnpmVgfmX"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import auth as google_auth\n",
        "    google_auth.authenticate_user()\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUU7z4FjJS90"
      },
      "source": [
        "# Upload to a GCP Cloud Storage Bucket\n",
        "\n",
        "To get the data into Vertex AI, we must first put it in a bucket as a CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3nbLg1cKJpJ"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "client = storage.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dAkAU5ALnUo"
      },
      "outputs": [],
      "source": [
        "bucket = client.bucket(STORAGE_BUCKET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTo7-_oJL_dZ"
      },
      "outputs": [],
      "source": [
        "# Upload our files to that bucket\n",
        "for filename in ['train.csv', 'test.csv']:\n",
        "    upload_path = os.path.join('raw', filename)\n",
        "    blob = bucket.blob(upload_path)\n",
        "    blob.upload_from_filename(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArK3cfKsdT1x"
      },
      "source": [
        "# Train and Deploy a Model on GCP\n",
        "We'll use the original features to train an AutoML model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGjrD-k3dsCN"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "dataset = aiplatform.TabularDataset.create(\n",
        "    display_name=\"form13-raw\",\n",
        "    gcs_source=os.path.join(\"gs://\", STORAGE_BUCKET, 'raw', 'train.csv'),\n",
        ")\n",
        "dataset.wait()\n",
        "\n",
        "print(f'\\tDataset: \"{dataset.display_name}\"')\n",
        "print(f'\\tname: \"{dataset.resource_name}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaSPuk31N2xS"
      },
      "outputs": [],
      "source": [
        "job = aiplatform.AutoMLTabularTrainingJob(\n",
        "    display_name='form13-raw',\n",
        "    optimization_prediction_type='classification'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fqf44y_G8vi1"
      },
      "outputs": [],
      "source": [
        "model = job.run(\n",
        "    dataset=dataset,\n",
        "    target_column='target',\n",
        "    training_fraction_split=0.8,\n",
        "    validation_fraction_split=0.1,\n",
        "    test_fraction_split=0.1,\n",
        "    model_display_name='form13-raw',\n",
        "    disable_early_stopping=False,\n",
        "    budget_milli_node_hours=1000,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint = model.deploy(machine_type='n1-standard-4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt03COEXxKOH"
      },
      "source": [
        "This job will run for an hour.  That's the minimum time for an AutoML job.  We're going to move on while that runs.  You can check on the job later in the [Google Cloud Console](https://console.cloud.google.com/) to see the results.  There's a link to the specific job in the output of the cell above.\n",
        "\n",
        "\n",
        "The model.deploy command will create an endpoint where you can make batch predictions."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "vertex_ai_raw.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
